### 1. Elasticsearch的节点类型

* Master节点 
  * 在Elasticsearch启动时，会选举出来一个Master节点。当某个节点启动后，然后 使用Zen Discovery机制找到集群中的其他节点，并建立连接。
  * 管理索引（创建索引、删除索引）、分配分片 
  * 维护元数据 
  * 管理集群节点状态 
  * 不负责数据写入和查询，比较轻量级 
* DataNode节点
  * 主要负责： 数据写入、数据检索
  * 大部分Elasticsearch的压力都在DataNode节点上 

### 2. 分片和副本机制 

* 分片
  * Elasticsearch是一个分布式的搜索引擎，索引的数据也是分成若干部分，分布在不同的服务器节点中 分布在不同服务器节点中的索引数据，就是分片（Shard）
  * 一个索引（index）由多个shard（分片）组成，而分片是分布在不同的服务器上的
  * Elasticsearch会自动 管理分片，如果发现分片分布不均衡，就会自动迁移
* 副本 
  * 每一个分片都会有对应的副本

**指定分片、副本数量**

```http
PUT /job_idx_shard_temp
{
	"mappings": {
		"properties": {
			"name": {
				"type": "keyword",
				"index": true,
				"store": true
			},
			"sex": {
				"type": "integer",
				"index": true,
				"store": true
			},
			"age": {
				"type": "integer",
				"index": true,
				"store": true
			},
			"book": {
				"type": "text",
				"index": true,
				"store": true,
				"analyzer": "ik_smart",
				"search_analyzer": "ik_smart"
			},
			"address": {
				"type": "text",
				"index": true,
				"store": true
			}
		}
	},
	"settings":{
	    "number_of_shards":3,
	    "number_of_replicas":2
	}
}
```

### 3. 重要工作流程

#### 3.1 写入原理

![image-20220219164344352](C:\Users\steven\AppData\Roaming\Typora\typora-user-images\image-20220219164344352.png)

* 选择任意一个DataNode发送请求，例如：node2。此时，node2就成为一个 coordinating node（协调节点） 
* 计算得到文档要写入的分片 `shard = hash(routing) % number_of_primary_shards`   routing 是一个可变值，默认是文档的 _id 
* coordinating node会进行路由，将请求转发给对应的primary shard所在的 DataNode（假设primary shard在node1、replica shard在node2）
* node1节点上的Primary Shard处理请求，写入数据到索引库中，并将数据同步到 Replica shard
* Primary Shard和Replica Shard都保存好了文档，返回client 

#### 3.2 检索原理

![image-20220219164548659](C:\Users\steven\AppData\Roaming\Typora\typora-user-images\image-20220219164548659.png)

* client发起查询请求，某个DataNode接收到请求，该DataNode就会成为协调节点 （Coordinating Node） 
* 协调节点（Coordinating Node）将查询请求广播到每一个数据节点，这些数据节 点的分片会处理该查询请求
* 每个分片进行数据查询，将符合条件的数据放在一个优先队列中，并将这些数据 的文档ID、节点信息、分片信息返回给协调节点
* 协调节点将所有的结果进行汇总，并进行全局排序
* 协调节点向包含这些文档ID的分片发送get请求，对应的分片将文档数据返回给协调节点，最后协调节点将数据返回给客户端 

### 4. Elasticsearch准实时索引实现 

**溢写到文件系统缓存 **

当数据写入到ES分片时，会首先写入到内存中，然后通过内存的buffer生成一个 segment，并刷到文件系统缓存中，数据可以被检索（注意不是直接刷到磁盘） ES中默认1秒，refresh一次 

**写translog保障容错 **

在写入到内存中的同时，也会记录translog日志，在refresh期间出现异常，会根据translog来进行数据恢复 等到文件系统缓存中的segment数据都刷到磁盘中，清空translog文件

**flush到磁盘**

ES默认每隔30分钟会将文件系统缓存的数据刷入到磁盘

**segment合并 **

Segment太多时，ES定期会将多个segment合并成为大的segment，减少索引查询时 IO开销，此阶段ES会真正的物理删除（之前执行过的delete的数据） 

### 5. 手工控制搜索结果精准度 

match 默 认的ES执行搜索的时候，operator就是or。

 "minimum_should_match": "68%"  指定匹配度

```http
GET /test_index/_search
{
  "query": {
    "match":{
      "address":{
        "query":"广州深圳",
        "operator":"and"
      }
    }
  }
}
```

上述语句，ES底层会自动转换为一下语句

```http
GET /test_index/_search
{
	"query": {
		"bool": {
			"must": [
				{
					"match": {
						"address": "广州"
					}
				},
				{
					"match": {
						"address": "深圳"
					}
				}
			]
		}
	}
}
```

**boost权重控制**

增加权重属性"boost" : 1 ，值越大权重越高

**基于dis_max实现best fields策略进行多字段搜索**

搜索的document中的某一个field，尽可能多的匹配搜索条件

* 优点：精确匹配的数据可以尽可能的排列在最前端，且可以通过 minimum_should_match来去除长尾数据，避免长尾数据字段对排序结果的影响。
* 缺点：相对排序不均匀

dis_max语法： 直接获取搜索的多条件中的，单条件query相关度分数最 高的数据，以这个数据做相关度排序

```http
GET /test_index/_search
{
  "query": {
    "dis_max":{
      "queries":[
        {
          "match": {
              "address": "广州"
          }
        },
        {
          "match": {
              "address": "深圳"
          }
        }
      ]
    }
  }
}
```

**基于tie_breaker参数优化dis_max搜索效果**

dis_max是将多个搜索query条件中相关度分数最高的用于结果排序，忽略其他 query分数，在某些情况下，可能还需要其他query条件中的相关度介入最终的结果 排序，这个时候可以使用tie_breaker参数来优化dis_max搜索.

tie_breaker参数 代表的含义是：将其他query搜索条件的相关度分数乘以参数值，再参与到结果排 序中。如果不定义此参数，相当于参数值为0。所以其他query条件的相关度分数被忽略

```http
GET /test_index/_search
{
  "query": {
    "dis_max":{
      "queries":[
        {
          "match": {
              "address": "广州"
          }
        },
        {
          "match": {
              "remark": "java"
          }
        }
      ],
      "tie_breaker":0.5
    }
  }
}
```

**使用multi_match简化dis_max+tie_breaker **

使用multi_match语法为：其中type常用的有best_fields和most_fields。^n代表权重， 相当于"boost":n。 

```http
GET /test_index/_search
{
  "query": {
    "multi_match":{
      "query": "rod java developer",
      "fields": ["name", "remark^2"],
      "type": "best_fields",
      "tie_breaker": 0.5,
      "minimum_should_match" : "50%"
    }
  }
}
```

**cross fields搜索 **

一个唯一的标识，分部在多个fields中，使用这种唯一标识 搜索数据就称为cross fields搜索。如：人名可以分为姓和名，地址可以分为省、 市、区县、街道等。那么使用人名或地址来搜索document，就称为cross fields搜 索。

实现这种搜索，一般都是使用most fields搜索策略。因为这就不是一个field 的问题。

Cross fields搜索策略，是从多个字段中搜索条件数据。默认情况下，和most fields搜索的逻辑是一致的，计算相关度分数是和best fields策略一致的。一般 来说，如果使用cross fields搜索策略，那么都会携带一个额外的参数operator。 用来标记搜索条件如何在多个字段中匹配。

```http
GET /test_index/_search
{
  "query": {
    "multi_match":{
      "query": "java developer",
      "fields": ["name", "remark^2"],
      "type": "cross_fields",
      "operator": "and"
    }
  }
}
```

most field策略问题：most fields策略是尽可能匹配更多的字段，所以会导致 精确搜索结果排序问题。

又因为cross fields搜索，不能使用 minimum_should_match来去除长尾数据。 所以在使用most fields和cross fields策略搜索数据的时候，都有不同的缺 陷。所以商业项目开发中，都推荐使用best fields策略实现搜索。 

**copy_to组合fields **

copy_to : 就是将多个字段，复制到一个字段中，实现一个多字段组合。copy_to 可以解决cross fields搜索问题，在商业项目中，也用于解决搜索条件默认字段问 题。

如果需要使用copy_to语法，则需要在定义index的时候，手工指定mapping映射策略

```http
PUT /test_index/_mapping
{
  "properties": {
    "provice":{
      "type": "text",
       "analyzer": "standard",
       "copy_to": "address"
    },
    "city":{
      "type": "text",
       "analyzer": "standard",
       "copy_to": "address"
    },
    "street":{
      "type": "text",
       "analyzer": "standard",
       "copy_to": "address"
    },
    "address":{
      "type": "text",
       "analyzer": "standard"
    }
  }
}
```

provice、city、street三个字段的值，会自动复制到address字段 中，实现一个字段的组合。那么在搜索地址的时候，就可以在address字段中做条 件匹配，从而避免most fields策略导致的问题.维护数据的时候，不需对 address字段特殊的维护

**近似匹配 **

1. match phrase:短语搜索。就是搜索条件不分词。代表搜索条件不可分割。 

   ```http
   GET /test_index/_search
   {
     "query": {
       "match_phrase":{
         "remark": "java assistant"
       }
     }
   }
   ```

2. 使用match phrase做搜 索的时候，也是和match类似，首先对搜索条件进行分词-analyze。将搜索条件拆 分成hello和world

3. ES在做分词的时候，除了将数据切分外，还会保留 一个position。position代表的是这个词在整个数据中的下标.如果hello和world都在某个document的某个field出现时，那么检查这两个匹配到的单词的position是否是连续的如果是连续的，代表匹配成功，如果是不连续的，则匹配失败

4. slop代表match phrase短语搜 索的时候，单词最多移动多少次，可以实现数据匹配在所有匹配结果中，多个单 词距离越近，相关度评分越高，排序越靠前。 

### 4. 总结

使用match和proximity search实现召回率和精准度平衡。

* 召回率：召回率就是搜索结果比率
* 精准度：就是搜索结果的准确率
* 那么如果需要在结果中兼顾召回率和精准度的时候，就需要将match和 proximity search混合使用，来得到搜索结果。

### 5.其他搜索

**前缀搜索 prefix search **

```http
GET /test_index/_search
{
    "query":{
        "prefix":{
            "remark.keyword":{
                "value": "j"
            }
        }
    }
}
```

针对前缀搜索，是对keyword类型字段而言。而keyword类型字段数据大小 写敏感。 

前缀搜索效率比较低。前缀搜索不会计算相关度分数。前缀越短，效率越低。 如果使用前缀搜索，建议使用长前缀。因为前缀搜索需要扫描完整的索引内容，所 以前缀越长，相对效率越高

**通配符搜索**

```http
GET /test_index/_search
{
    "query":{
        "wildcard":{
            "remark.keyword":{
                "value": "j*d*"
            }
        }
    }
}
```

性能也很低，也是需要扫描完整的索引。不推荐使用

**正则搜索**

ES支持正则表达式。可以在倒排索引或keyword类型字段中使用。

```http
GET /test_index/_search
{
    "query":{
        "regexp":{
            "remark.keyword":"[A-z].*"
        }
    }
}
```

性能也很低，需要扫描完整索引。

**搜索推荐**

```http
GET /test_index/_search
{
    "query":{
        "match_phrase_prefix":{
            "remark":{  
                "query" : "java d",
                "slop": 10,
                "max_expansions": 10
            }
        }
    }
}
```

因为效率较低如果必须使用，则一定要使用参数max_expansions。

**fuzzy模糊搜索技术**

```http
GET /test_index/_search
{
    "query":{
        "fuzzy":{
            'remark':{
                "value" : "jave",
                "fuzziness": 1
            }
        }
    }
}
```













